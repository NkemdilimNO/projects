{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e9PnxNiWUw5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries to help with reading and manipulating data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Libraries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_theme(style='darkgrid')\n",
        "\n",
        "# Removes the limit for the number of displayed columns\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "# Sets the limit for the number of displayed rows\n",
        "pd.set_option(\"display.max_rows\", 200)\n",
        "\n",
        "# to scale the data using z-score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# to compute distances\n",
        "from scipy.spatial.distance import cdist, pdist\n",
        "\n",
        "# to perform k-means clustering and compute silhouette scores\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# to visualize the elbow curve and silhouette scores\n",
        "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
        "\n",
        "# to perform hierarchical clustering, compute cophenetic correlation, and create dendrograms\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet\n",
        "\n",
        "# to suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "zeF8YaNKDPyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yellowbrick"
      ],
      "metadata": {
        "id": "1_H3W4jU6fsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3679d126-b773-423f-b776-f6ff4f0088d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yellowbrick in /usr/local/lib/python3.10/dist-packages (1.5)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (3.7.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (1.26.4)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (0.12.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.3.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PTNr8pX26gRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Overview\n",
        "\n",
        "- Observations\n",
        "- Sanity checks"
      ],
      "metadata": {
        "id": "UvpMDcaaMKtI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the dataset"
      ],
      "metadata": {
        "id": "Hm7KgGlU3IIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JIdrFpBFBGCh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "93f2bd21-544d-47df-ff1e-3eac7d7604a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Complete the code to import the data\n",
        "data = pd.read_csv('/content/drive/MyDrive/stock_data.csv')"
      ],
      "metadata": {
        "id": "7IQ5WZ5kxovh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview of the Dataset"
      ],
      "metadata": {
        "id": "EmcUelfD3gP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The initial steps to get an overview of any dataset is to:\n",
        "- observe the first few rows of the dataset, to check whether the dataset has been loaded properly or not\n",
        "- get information about the number of rows and columns in the dataset\n",
        "- find out the data types of the columns to ensure that data is stored in the preferred format and the value of each property is as expected.\n",
        "- check the statistical summary of the dataset to get an overview of the numerical columns of the data"
      ],
      "metadata": {
        "id": "QAOnjt1P73xz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the shape of the dataset"
      ],
      "metadata": {
        "id": "hwQCJyE03W61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking shape of the data\n",
        "data.shape"
      ],
      "metadata": {
        "id": "UieopQYXxovh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset has 340 rows and 15 columns"
      ],
      "metadata": {
        "id": "tgnXegLH_VFD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ho3NqWNoYDSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Displaying few rows of the dataset"
      ],
      "metadata": {
        "id": "v85RmCY83qfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's view a sample of the data\n",
        "data.sample(n=10, random_state=1)"
      ],
      "metadata": {
        "id": "KPRlYPGnxovh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the data types of the columns for the dataset"
      ],
      "metadata": {
        "id": "D6y0mZgY3zA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the column names and datatypes\n",
        "data.info()"
      ],
      "metadata": {
        "id": "rxWppuwfxovi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Ticker Symbol, Security, GICS Sector and GICS Sub Industry are categorical variables with 340 levels that indicate each stock's name\n",
        "- The remaining variables are of type int (integer)"
      ],
      "metadata": {
        "id": "9AXt_YEO_2f1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a copy of original data"
      ],
      "metadata": {
        "id": "Bzr4r3ua3usT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copying the data to another variable to avoid any changes to original data\n",
        "df = data.copy()"
      ],
      "metadata": {
        "id": "lYr1iFl7xovi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking for duplicates and missing values"
      ],
      "metadata": {
        "id": "7qcQovqA31ZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for duplicate values\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "WapzauPrhmV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no duplicate entries"
      ],
      "metadata": {
        "id": "RgKCuCQmCDzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for missing values in the data\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "WLO-3tE0xovj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no missing values in our data"
      ],
      "metadata": {
        "id": "_mPQd5HRAqZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping the serial no. column as it does not provide any information\n",
        "df.drop(\"Ticker Symbol\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "naA6cNsjAswS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistical summary of the dataset"
      ],
      "metadata": {
        "id": "sSju8Xrl4HZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's check the statistical summary of the data.**"
      ],
      "metadata": {
        "id": "eW4-5-GUhmV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include='all').T"
      ],
      "metadata": {
        "id": "UmZMcr6Jxovm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Observations***\n",
        "- There are 340 securities listed and each column has a value for each security\n",
        "- The avg current price is 80.86 with the lowest price of 4.50 and the highest current price of 1,274.95\n",
        "- The average price change is +4.08 with the lowest price change of -47.13 and the highest price change of +55.05\n",
        "- The average volatility rate is 1.53 with the lowest of 0.733 and the highest of 4.58\n",
        "- The average ROE is 39.60 with the lowest of 1.0 and the highest of 917\n",
        "- The average Cash Ratio is 70.02 with the lowest of 0 and the highest of 958\n",
        "- The average Net Cash Flow is 55,537,620 with the lowest of -11,208,000,000 and the highest of 20,764,000,000\n",
        "- The average Net Income is 1,494,384,602 with the lowest of -23,528,000,000 and the highest of 24,442,000,000\n",
        "- The average Earnings Per Share is 2.7766 with the lowest of -61.2 and the highest of 50.09\n",
        "- The average Estimated Shares Outstanding is 577,028,337 with the lowest of 27,672,156 and the highest of 6,159,292,035\n",
        "- The average P/E Ratio is 32.61 with the lowest of 2.935 and the highest of 528.039\n",
        "- The average P/B Ratio is -1.72 with the lowest of -76.12 and the highest of 129.06"
      ],
      "metadata": {
        "id": "x5majVAwbtOf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "\n",
        "- EDA is an important part of any project involving data.\n",
        "- It is important to investigate and understand the data better before building a model with it.\n",
        "- A few questions have been mentioned below which will help you approach the analysis in the right manner and generate insights from the data.\n",
        "- A thorough analysis of the data, in addition to the questions mentioned below, should be done."
      ],
      "metadata": {
        "id": "__7ciGcIDPyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions**:\n",
        "\n",
        "1. What does the distribution of stock prices look like?\n",
        "2. The stocks of which economic sector have seen the maximum price increase on average?\n",
        "3. How are the different variables correlated with each other?\n",
        "4. Cash ratio provides a measure of a company's ability to cover its short-term obligations using only cash and cash equivalents. How does the average cash ratio vary across economic sectors?\n",
        "5. P/E ratios can help determine the relative value of a company's shares as they signify the amount of money an investor is willing to invest in a single share of a company per dollar of its earnings. How does the P/E ratio vary, on average, across economic sectors?"
      ],
      "metadata": {
        "id": "oEyqzdJBb0jU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Univariate analysis"
      ],
      "metadata": {
        "id": "OhOvFOh2xovm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA\n",
        "\n",
        "- It is a good idea to explore the data once again after manipulating it."
      ],
      "metadata": {
        "id": "KNzFis7eEaXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to plot a boxplot and a histogram along the same scale.\n",
        "\n",
        "\n",
        "def histogram_boxplot(df, feature, figsize=(12, 7), kde=False, bins=None):\n",
        "    \"\"\"\n",
        "    Boxplot and histogram combined\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    figsize: size of figure (default (12,7))\n",
        "    kde: whether to the show density curve (default False)\n",
        "    bins: number of bins for histogram (default None)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
        "        nrows=2,  # Number of rows of the subplot grid= 2\n",
        "        sharex=True,  # x-axis will be shared among all subplots\n",
        "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
        "        figsize=figsize,\n",
        "    )  # creating the 2 subplots\n",
        "    sns.boxplot(\n",
        "        data=df, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
        "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
        "    sns.histplot(\n",
        "        data=df, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
        "    ) if bins else sns.histplot(\n",
        "        data=df, x=feature, kde=kde, ax=ax_hist2\n",
        "    )  # For histogram\n",
        "    ax_hist2.axvline(\n",
        "        df[feature].mean(), color=\"green\", linestyle=\"--\"\n",
        "    )  # Add mean to the histogram\n",
        "    ax_hist2.axvline(\n",
        "        df[feature].median(), color=\"black\", linestyle=\"-\"\n",
        "    )  # Add median to the histogram"
      ],
      "metadata": {
        "id": "koAdN4bHxovm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Current Price`**"
      ],
      "metadata": {
        "id": "jtkm7s8qxovn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(df, 'Current Price')"
      ],
      "metadata": {
        "id": "D_dHQlOaxovo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution for Current Price is Right skewed and has a few outliers"
      ],
      "metadata": {
        "id": "mDEVrznnk7_o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Price Change`**"
      ],
      "metadata": {
        "id": "O3PMFYI2xovp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(df, 'Price Change')"
      ],
      "metadata": {
        "id": "C50gCvn8xovp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Price Change is uniformally distributed"
      ],
      "metadata": {
        "id": "n34D5w5MlDzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Volatility`**"
      ],
      "metadata": {
        "id": "xWAFVF2Jxovq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(df, 'Volatility')"
      ],
      "metadata": {
        "id": "j7WNBn2vxovr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution for volatility is slightly Right skewed and bimodal"
      ],
      "metadata": {
        "id": "SOnDvhfclQQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`ROE`**"
      ],
      "metadata": {
        "id": "igMrbRNVxovr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(df, 'ROE')"
      ],
      "metadata": {
        "id": "1p9fiaHnxovr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution for ROE is Right skewed and has a few outliers"
      ],
      "metadata": {
        "id": "X92bmCTalZtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Cash Ratio`**"
      ],
      "metadata": {
        "id": "oyliEU6txovs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(df, 'Cash Ratio')"
      ],
      "metadata": {
        "id": "IcELmSqvxovs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution for Cash Ratio is Right skewed, is bimodal and has a few outliers"
      ],
      "metadata": {
        "id": "IKQpTQd5lbwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Net Cash Flow`**"
      ],
      "metadata": {
        "id": "QONKhDX1xovs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(df, 'Net Cash Flow')"
      ],
      "metadata": {
        "id": "zJMaygxkxovs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Net Cash Flow is uniformally distributed and has a few outliers"
      ],
      "metadata": {
        "id": "2DUqFk69lj6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Net Income`**"
      ],
      "metadata": {
        "id": "6oAJaiEWxovt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(df, 'Net Income')"
      ],
      "metadata": {
        "id": "91MajI0V-J6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Net Income is uniformally distributed and has a few outliers"
      ],
      "metadata": {
        "id": "MsKv8Kr-lszY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Earnings Per Share`**"
      ],
      "metadata": {
        "id": "hPpOoaVtxovt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(df, 'Earnings Per Share')"
      ],
      "metadata": {
        "id": "1xCIMy1t-Ok0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Earning Per Share is uniformally distributed and has a few outliers"
      ],
      "metadata": {
        "id": "dftsnrX4lvND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Estimated Shares Outstanding`**"
      ],
      "metadata": {
        "id": "oZBjr5Tqxovu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(df, 'Estimated Shares Outstanding')"
      ],
      "metadata": {
        "id": "wUl5ql55-PX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estimated Shares Outstanding is right skewed with outliers"
      ],
      "metadata": {
        "id": "U96yx0rmlz72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`P/E Ratio`**"
      ],
      "metadata": {
        "id": "zGNfsAUqxovv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(df, 'P/E Ratio')"
      ],
      "metadata": {
        "id": "-3L3wDgIxovv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "P/E Ratio is right skewed with outliers"
      ],
      "metadata": {
        "id": "xLFBX5zVl7VY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`P/B Ratio`**"
      ],
      "metadata": {
        "id": "L8y-ZYq4-cSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(df, 'P/B Ratio')"
      ],
      "metadata": {
        "id": "c1I1Ec5A-Yy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "P/B Ratio is uniformally distributed"
      ],
      "metadata": {
        "id": "v1u-ddD1l-ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create labeled barplots\n",
        "\n",
        "\n",
        "def labeled_barplot(df, feature, perc=False, n=None):\n",
        "    \"\"\"\n",
        "    Barplot with percentage at the top\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    perc: whether to display percentages instead of count (default is False)\n",
        "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
        "    \"\"\"\n",
        "\n",
        "    total = len(df[feature])  # length of the column\n",
        "    count = df[feature].nunique()\n",
        "    if n is None:\n",
        "        plt.figure(figsize=(count + 1, 5))\n",
        "    else:\n",
        "        plt.figure(figsize=(n + 1, 5))\n",
        "\n",
        "    plt.xticks(rotation=90, fontsize=15)\n",
        "    ax = sns.countplot(\n",
        "        data=df,\n",
        "        x=feature,\n",
        "        palette=\"Paired\",\n",
        "        order=df[feature].value_counts().index[:n].sort_values(),\n",
        "    )\n",
        "\n",
        "    for p in ax.patches:\n",
        "        if perc == True:\n",
        "            label = \"{:.1f}%\".format(\n",
        "                100 * p.get_height() / total\n",
        "            )  # percentage of each class of the category\n",
        "        else:\n",
        "            label = p.get_height()  # count of each level of the category\n",
        "\n",
        "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
        "        y = p.get_height()  # height of the plot\n",
        "\n",
        "        ax.annotate(\n",
        "            label,\n",
        "            (x, y),\n",
        "            ha=\"center\",\n",
        "            va=\"center\",\n",
        "            size=12,\n",
        "            xytext=(0, 5),\n",
        "            textcoords=\"offset points\",\n",
        "        )  # annotate the percentage\n",
        "\n",
        "    plt.show()  # show the plot"
      ],
      "metadata": {
        "id": "sPdsvnaV-Wim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`GICS Sector`**"
      ],
      "metadata": {
        "id": "3kNIAnHOxovw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(df, 'GICS Sector', perc=True)"
      ],
      "metadata": {
        "id": "5X8sRNXWxovw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['GICS Sector'].value_counts()"
      ],
      "metadata": {
        "id": "wcP2RG6RE5vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['GICS Sector'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "EKkpNJOiFDN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Observations***\n",
        "- 15.6% or 53 of the stocks are of the GICS Sector \"Industrials\"\n",
        "- 14.4% or 49, Financials           \n",
        "- 11.8% or 40, Health Care\n",
        "- 11.8% or 40, Consumer Discretionary  \n",
        "- 9.7% or 33, Information Technology"
      ],
      "metadata": {
        "id": "V9r7gKt1FRy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`GICS Sub Industry`**"
      ],
      "metadata": {
        "id": "FAwCc-Utxovw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_barplot(df, 'GICS Sub Industry', perc=False)"
      ],
      "metadata": {
        "id": "bHBpKqKhxovw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's display the top 5 Sub Industries\n",
        "labeled_barplot(df, 'GICS Sub Industry', n=5, perc=True)"
      ],
      "metadata": {
        "id": "MDdEPhV4Ko7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['GICS Sub Industry'].value_counts(normalize=False)"
      ],
      "metadata": {
        "id": "cxltqgL4LtKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Observations***\n",
        "- 16 or 4.7% of stocks are labeled GICS Sub Industry Gas Exploration & Production\n",
        "- 14 or 4.1% are REITs\n",
        "- 14 or 4.1% are Industrial Conglomerates\n",
        "- 12 or 3.5% are Electric Utilities\n",
        "- 12 or 3.5% are Internet Software & Services"
      ],
      "metadata": {
        "id": "tKeSrc0ZMJ0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bivariate Analysis"
      ],
      "metadata": {
        "id": "Ga_huJrnhmWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation check\n",
        "plt.figure(figsize=(15, 7))\n",
        "sns.heatmap(\n",
        "    df.corr(), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\"\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BpJxawjAhmWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Observations***\n",
        "- As expected, Earnings Per Share is positively correlated with Current Price and Net Income\n",
        "- P/E Ratio is positively correlated with Current Price, Volatility and negatively correlated with Net Income and Earnings per Share.\n",
        "- Net Income is positively correlated with Earnings Per Share and Estimated Shares Outstanding and negatively correlated with Volatility and ROE\n"
      ],
      "metadata": {
        "id": "4Y2jmvw-hqdD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's check the stocks of which economic sector have seen the maximum price increase on average.**"
      ],
      "metadata": {
        "id": "-_mfWBWrxovx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.barplot(data=df, x='GICS Sector', y='Price Change', ci=False)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tExQEx_Kxovx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['GICS Sector'])['Price Change'].mean().sort_values(ascending = False)"
      ],
      "metadata": {
        "id": "uSM0qSEqRMPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Observations***\n",
        "- Health Care stocks saw the highest price increase by 9.59 followed by Consumer Staples and Information Technology\n",
        "- Energy stocks had the highest price drop of 10.22"
      ],
      "metadata": {
        "id": "VVYUbtvPQfM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.barplot( )  ## Complete the code to choose the right variables\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TM1MWi68O0a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lb5hKN6sOtKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cash ratio provides a measure of a company's ability to cover its short-term obligations using only cash and cash equivalents. Let's see how the average cash ratio varies across economic sectors.**"
      ],
      "metadata": {
        "id": "oknJ5SYxxovx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.barplot(data=df, x='GICS Sector', y='Cash Ratio', ci=False) ## Complete the code to choose the right variables\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qS6Huw1Pxovx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['GICS Sector'])['Cash Ratio'].mean().sort_values(ascending = False)"
      ],
      "metadata": {
        "id": "mtzMlcLuSFdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Observations***\n",
        "\n",
        "The sectors with the healthiest Cash Ratio are:\n",
        "- IT\n",
        "- Telecommunications Services\n",
        "- Health Care"
      ],
      "metadata": {
        "id": "l80zQdPniexi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SxG4dcWykAvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**P/E ratios can help determine the relative value of a company's shares as they signify the amount of money an investor is willing to invest in a single share of a company per dollar of its earnings. Let's see how the P/E ratio varies, on average, across economic sectors.**"
      ],
      "metadata": {
        "id": "FYVjpY12xovy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.barplot(data=df, x='GICS Sector', y='P/E Ratio', ci=False) ## Complete the code to choose the right variables\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PEdSTaU6xovy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['GICS Sector'])['P/E Ratio'].mean().sort_values(ascending = False)"
      ],
      "metadata": {
        "id": "iHahRDOiSeac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***Observations***\n",
        "The sectors with the highest P/E ratios that help determine the value of a company's shares are:\n",
        "- Energy\n",
        "- IT\n",
        "- Real Estate\n",
        "- Health Care\n",
        "- Consumer Discretionary\n"
      ],
      "metadata": {
        "id": "E6OP009VjV4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Volatility accounts for the fluctuation in the stock price. A stock with high volatility will witness sharper price changes, making it a riskier investment. Let's see how volatility varies, on average, across economic sectors.**"
      ],
      "metadata": {
        "id": "K6iNTVu9xovy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.barplot(data=df, x='GICS Sector', y='Volatility', ci=False) ## Complete the code to choose the right variables\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3T20W0lUxovy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['GICS Sector'])['Volatility'].mean().sort_values(ascending = False)"
      ],
      "metadata": {
        "id": "AZLJEKU7SigX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sectors with high volatility and, therefore, are riskier investments are:\n",
        "- Energy\n",
        "- Materials\n",
        "- IT\n"
      ],
      "metadata": {
        "id": "Ix5jM6G0jsZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "- Duplicate value check\n",
        "- Missing value treatment\n",
        "- Outlier check\n",
        "- Feature engineering (if needed)\n",
        "- Any other preprocessing steps (if needed)"
      ],
      "metadata": {
        "id": "pVn5toJ7MKte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outlier Check\n",
        "\n",
        "- Let's plot the boxplots of all numerical columns to check for outliers."
      ],
      "metadata": {
        "id": "v_62yc6Yxovy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "num_col = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "for i, variable in enumerate(num_col):\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    plt.boxplot(df[variable], whis=1.5)\n",
        "    plt.tight_layout()\n",
        "    plt.title(variable)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "txVPWkWkxovy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaling\n",
        "\n",
        "- Let's scale the data before we proceed with clustering."
      ],
      "metadata": {
        "id": "ZWVdMzObxovz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling the data set before clustering\n",
        "scaler = StandardScaler()\n",
        "subset = df[num_col].copy()\n",
        "subset_scaled = scaler.fit_transform(subset)"
      ],
      "metadata": {
        "id": "PO1s-k6Wxovz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dataframe of the scaled data\n",
        "subset_scaled_df = pd.DataFrame(subset_scaled, columns=subset.columns)"
      ],
      "metadata": {
        "id": "KXm8ELysxovz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-means Clustering"
      ],
      "metadata": {
        "id": "g65eWNkmUw55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking Elbow Plot"
      ],
      "metadata": {
        "id": "FU-lhW1EQrlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_means_df = subset_scaled_df.copy()"
      ],
      "metadata": {
        "id": "bw0QvsdDxovz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clusters = range(1, 15)\n",
        "meanDistortions = []\n",
        "\n",
        "for k in clusters:\n",
        "    model = KMeans(n_clusters=k, random_state=1)\n",
        "    model.fit(subset_scaled_df)\n",
        "    prediction = model.predict(k_means_df)\n",
        "    distortion = (\n",
        "        sum(np.min(cdist(k_means_df, model.cluster_centers_, \"euclidean\"), axis=1))\n",
        "        / k_means_df.shape[0]\n",
        "    )\n",
        "\n",
        "    meanDistortions.append(distortion)\n",
        "\n",
        "    print(\"Number of Clusters:\", k, \"\\tAverage Distortion:\", distortion)\n",
        "\n",
        "plt.plot(clusters, meanDistortions, \"bx-\")\n",
        "plt.xlabel(\"k\")\n",
        "plt.ylabel(\"Average Distortion\")\n",
        "plt.title(\"Selecting k with the Elbow Method\", fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vnkjMWZwxov0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KMeans(random_state=1)\n",
        "visualizer = KElbowVisualizer(model, k=(1, 15), timings=True)\n",
        "visualizer.fit(k_means_df)  # fit the data to the visualizer\n",
        "visualizer.show()  # finalize and render figure"
      ],
      "metadata": {
        "id": "2Y5ZXHDBxov0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's check the silhouette scores"
      ],
      "metadata": {
        "id": "1VIgju4dxrIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sil_score = []\n",
        "cluster_list = range(2, 15)\n",
        "for n_clusters in cluster_list:\n",
        "    clusterer = KMeans(n_clusters=n_clusters, random_state=1)\n",
        "    preds = clusterer.fit_predict((subset_scaled_df))\n",
        "    score = silhouette_score(k_means_df, preds)\n",
        "    sil_score.append(score)\n",
        "    print(\"For n_clusters = {}, the silhouette score is {})\".format(n_clusters, score))\n",
        "\n",
        "plt.plot(cluster_list, sil_score)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sNY8NHaYxov0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KMeans(random_state=1)\n",
        "visualizer = KElbowVisualizer(model, k=(2, 15), metric=\"silhouette\", timings=True)\n",
        "visualizer.fit(k_means_df)  # fit the data to the visualizer\n",
        "visualizer.show()  # finalize and render figure"
      ],
      "metadata": {
        "id": "91v0V1YMxov0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding optimal no. of clusters with silhouette coefficients\n",
        "visualizer = SilhouetteVisualizer(KMeans(3, random_state=1))  ## Complete the code to visualize the silhouette scores for certain number of clusters\n",
        "visualizer.fit(k_means_df)\n",
        "visualizer.show()"
      ],
      "metadata": {
        "id": "dKkXQIx3TbbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qjai7I3ZV9--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding optimal no. of clusters with silhouette coefficients\n",
        "visualizer = SilhouetteVisualizer(KMeans(4, random_state=1))  ## Complete the code to visualize the silhouette scores for certain number of clusters\n",
        "visualizer.fit(k_means_df)\n",
        "visualizer.show()"
      ],
      "metadata": {
        "id": "VjjxB6hqxov0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding optimal no. of clusters with silhouette coefficients\n",
        "visualizer = SilhouetteVisualizer(KMeans(7, random_state=1))  ## Complete the code to visualize the silhouette scores for certain number of clusters\n",
        "visualizer.fit(k_means_df)\n",
        "visualizer.show()"
      ],
      "metadata": {
        "id": "_ahnl9pm0Ngj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iiZJnegp0O4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Final Model"
      ],
      "metadata": {
        "id": "Vxy8D8CeQ0bg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's take 4 as the appropriate no. of clusters as the silhouette score is high enough and there is knick at 4 in the elbow curve.**"
      ],
      "metadata": {
        "id": "Ewa2aMRb0ffG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# final K-means model\n",
        "kmeans = KMeans(n_clusters=4, random_state=1)  ## Complete the code to choose the number of clusters\n",
        "kmeans.fit(k_means_df)"
      ],
      "metadata": {
        "id": "QqmDLWH-xov0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a copy of the original data\n",
        "df1 = df.copy()\n",
        "\n",
        "# adding kmeans cluster labels to the original and scaled dataframes\n",
        "k_means_df[\"KM_segments\"] = kmeans.labels_\n",
        "df1[\"KM_segments\"] = kmeans.labels_"
      ],
      "metadata": {
        "id": "MEQT6CZdxov0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster Profiling"
      ],
      "metadata": {
        "id": "iwpXRlGMxov1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "km_cluster_profile = df1.groupby(\"KM_segments\").mean()  ## Complete the code to groupby the cluster labels"
      ],
      "metadata": {
        "id": "OGFmfLfixov1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "km_cluster_profile[\"count_in_each_segment\"] = (\n",
        "    df1.groupby(\"KM_segments\")[\"Security\"].count().values  ## Complete the code to groupby the cluster labels\n",
        ")"
      ],
      "metadata": {
        "id": "9LW7b74oxov1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "km_cluster_profile.style.highlight_max(color=\"lightgreen\", axis=0)"
      ],
      "metadata": {
        "id": "HraXqc0oxov1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Complete the code to print the companies in each cluster\n",
        "for cl in df1[\"KM_segments\"].unique():\n",
        "    print(\"In cluster {}, the following companies are present:\".format(cl))\n",
        "    print(df1[df1[\"KM_segments\"] == cl][\"Security\"].unique())\n",
        "    print()"
      ],
      "metadata": {
        "id": "GTZKfxoCxov1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.groupby([\"KM_segments\", \"GICS Sector\"])['Security'].count()"
      ],
      "metadata": {
        "id": "xtXfzkUoxov2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "plt.suptitle(\"Boxplot of numerical variables for each cluster\")\n",
        "\n",
        "# selecting numerical columns\n",
        "num_col = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "for i, variable in enumerate(num_col):\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    sns.boxplot(data=df1, x=\"KM_segments\", y=variable)\n",
        "\n",
        "plt.tight_layout(pad=2.0)"
      ],
      "metadata": {
        "id": "mQ3VmIUMxov2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.groupby(\"KM_segments\").mean().plot.bar(figsize=(30,15))"
      ],
      "metadata": {
        "id": "d8WPb6FeWWZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights"
      ],
      "metadata": {
        "id": "nHZiakyR8otD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Cluster 0**:\n",
        "    - Net Income is very low for stocks in this cluster.\n",
        "    - Estimated Shares Outstanding is very low\n",
        "    - Net Cash Flow is almost 0 in this cluster\n",
        "\n",
        "- **Cluster 1**:\n",
        "    - Net Income is very high for stocks in this cluster.\n",
        "    - Estimated Shares Outstanding is moderate.\n",
        "    - Net Cash Flow is negative for this cluster 8\n",
        "\n",
        "\n",
        "- **Cluster 2**:\n",
        "    - Net Income is negative for stocks in this cluster.8\n",
        "    - Estimated Shares Outstanding is very low\n",
        "    - Net Cash Flow is negative for this cluster 8\n",
        "\n",
        "\n",
        "- **Cluster 3**:\n",
        "    - Net Income is low in this cluster\n",
        "    - Estimated Shares Outstanding is low\n",
        "    - Net Cash Flow is very low"
      ],
      "metadata": {
        "id": "Le_jQHF7W8hk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hierarchical Clustering"
      ],
      "metadata": {
        "id": "083oRHCMUw55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing Cophenetic Correlation"
      ],
      "metadata": {
        "id": "9md24iMdGsIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hc_df = subset_scaled_df.copy()"
      ],
      "metadata": {
        "id": "Uxu9EPMaxov2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of distance metrics\n",
        "distance_metrics = [\"euclidean\", \"chebyshev\", \"mahalanobis\", \"cityblock\"]\n",
        "\n",
        "# list of linkage methods\n",
        "linkage_methods = [\"single\", \"complete\", \"average\", \"weighted\"]\n",
        "\n",
        "high_cophenet_corr = 0\n",
        "high_dm_lm = [0, 0]\n",
        "\n",
        "for dm in distance_metrics:\n",
        "    for lm in linkage_methods:\n",
        "        Z = linkage(hc_df, metric=dm, method=lm)\n",
        "        c, coph_dists = cophenet(Z, pdist(hc_df))\n",
        "        print(\n",
        "            \"Cophenetic correlation for {} distance and {} linkage is {}.\".format(\n",
        "                dm.capitalize(), lm, c\n",
        "            )\n",
        "        )\n",
        "        if high_cophenet_corr < c:\n",
        "            high_cophenet_corr = c\n",
        "            high_dm_lm[0] = dm\n",
        "            high_dm_lm[1] = lm\n",
        "\n",
        "# printing the combination of distance metric and linkage method with the highest cophenetic correlation\n",
        "print('*'*100)\n",
        "print(\n",
        "    \"Highest cophenetic correlation is {}, which is obtained with {} distance and {} linkage.\".format(\n",
        "        high_cophenet_corr, high_dm_lm[0].capitalize(), high_dm_lm[1]\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "c7Wt_Hhixov2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's explore different linkage methods with Euclidean distance only.**"
      ],
      "metadata": {
        "id": "hDMwykEjxov2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list of linkage methods\n",
        "linkage_methods = [\"single\", \"complete\", \"average\", \"centroid\", \"ward\", \"weighted\"]\n",
        "\n",
        "\n",
        "high_cophenet_corr = 0\n",
        "high_dm_lm = [0, 0]\n",
        "\n",
        "for lm in linkage_methods:\n",
        "    Z = linkage(hc_df, metric=\"euclidean\", method=lm)\n",
        "    c, coph_dists = cophenet(Z, pdist(hc_df))\n",
        "    print(\"Cophenetic correlation for {} linkage is {}.\".format(lm, c))\n",
        "    if high_cophenet_corr < c:\n",
        "        high_cophenet_corr = c\n",
        "        high_dm_lm[0] = \"euclidean\"\n",
        "        high_dm_lm[1] = lm\n",
        "\n",
        "# printing the combination of distance metric and linkage method with the highest cophenetic correlation\n",
        "print('*'*100)\n",
        "print(\n",
        "    \"Highest cophenetic correlation is {}, which is obtained with {} linkage.\".format(\n",
        "        high_cophenet_corr, high_dm_lm[1]\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "-cEbtS7sxov2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's view the dendrograms for the different linkage methods with Euclidean distance.**"
      ],
      "metadata": {
        "id": "Hb5D9LOTxov2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking Dendrograms"
      ],
      "metadata": {
        "id": "vcwjui0aRJ2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list of linkage methods\n",
        "linkage_methods = [\"single\", \"complete\", \"average\", \"centroid\", \"ward\", \"weighted\"] ## Complete the code to add linkages\n",
        "\n",
        "# lists to save results of cophenetic correlation calculation\n",
        "compare_cols = [\"Linkage\", \"Cophenetic Coefficient\"]\n",
        "compare = []\n",
        "\n",
        "# to create a subplot image\n",
        "fig, axs = plt.subplots(len(linkage_methods), 1, figsize=(15, 30))\n",
        "\n",
        "# We will enumerate through the list of linkage methods above\n",
        "# For each linkage method, we will plot the dendrogram and calculate the cophenetic correlation\n",
        "for i, method in enumerate(linkage_methods):\n",
        "    Z = linkage(hc_df, metric=\"euclidean\", method=method)\n",
        "\n",
        "    dendrogram(Z, ax=axs[i])\n",
        "    axs[i].set_title(f\"Dendrogram ({method.capitalize()} Linkage)\")\n",
        "\n",
        "    coph_corr, coph_dist = cophenet(Z, pdist(hc_df))\n",
        "    axs[i].annotate(\n",
        "        f\"Cophenetic\\nCorrelation\\n{coph_corr:0.2f}\",\n",
        "        (0.80, 0.80),\n",
        "        xycoords=\"axes fraction\",\n",
        "    )\n",
        "\n",
        "    compare.append([method, coph_corr])"
      ],
      "metadata": {
        "id": "l4cgZ97txov3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create and print a dataframe to compare cophenetic correlations for different linkage methods\n",
        "df_cc = pd.DataFrame(compare, columns=compare_cols)\n",
        "df_cc = df_cc.sort_values(by=\"Cophenetic Coefficient\")\n",
        "df_cc"
      ],
      "metadata": {
        "id": "jLbweXaDxov3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating model using sklearn"
      ],
      "metadata": {
        "id": "AxFLzqndRPtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HCmodel = AgglomerativeClustering(n_clusters=4, affinity=\"euclidean\", linkage=\"average\")\n",
        "HCmodel.fit(hc_df)"
      ],
      "metadata": {
        "id": "cvogYnGVxov3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a copy of the original data\n",
        "df2 = df.copy()\n",
        "\n",
        "# adding hierarchical cluster labels to the original and scaled dataframes\n",
        "hc_df[\"HC_Clusters\"] = HCmodel.labels_\n",
        "df2[\"HC_Clusters\"] = HCmodel.labels_"
      ],
      "metadata": {
        "id": "rmsiS_Znxov3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cluster Profiling"
      ],
      "metadata": {
        "id": "8XpWm7cmxov3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_profile = df2.groupby(\"HC_Clusters\").mean()"
      ],
      "metadata": {
        "id": "hs8U6SZ8xov3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_profile[\"count_in_each_segments\"] = (\n",
        "    df2.groupby(\"HC_Clusters\")[\"Current Price\"].count().values\n",
        ")"
      ],
      "metadata": {
        "id": "LSES0Cjxxov4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_profile.style.highlight_max(color=\"lightgreen\", axis=0)"
      ],
      "metadata": {
        "id": "jx55RjV_xov4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see the names of the securities in each cluster\n",
        "for cl in df2[\"HC_Clusters\"].unique():\n",
        "    print(\"In cluster {}, the following securities are present:\".format(cl))\n",
        "    print(df2[df2[\"HC_Clusters\"] == cl][\"Security\"].unique())\n",
        "    print()"
      ],
      "metadata": {
        "id": "jG2ecMWgxov4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.groupby([\"HC_Clusters\", \"GICS Sector\"])['Security'].count()"
      ],
      "metadata": {
        "id": "Iwykr0MGxov4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "plt.suptitle(\"Boxplot of numerical variables for each cluster\")\n",
        "\n",
        "for i, variable in enumerate(num_col):\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    sns.boxplot(data=df2, x=\"HC_Clusters\", y=variable)\n",
        "\n",
        "plt.tight_layout(pad=2.0)"
      ],
      "metadata": {
        "id": "EqcftWIaxov5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.groupby(\"HC_Clusters\").mean().plot.bar(figsize=(30,15))"
      ],
      "metadata": {
        "id": "bbc_IkQcM_wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Cluster 0**:\n",
        "    - Net Income is moderate for stocks in this cluster.\n",
        "    - Estimated Shares Outstanding is low\n",
        "    - Net Cash Flow is very low.\n",
        "\n",
        "- **Cluster 1**:\n",
        "    - Net Income is high for stocks in this cluster.\n",
        "    - Estimated Shares Outstanding extremely low\n",
        "    - Net Cash Flow is negative for this cluster\n",
        "\n",
        "\n",
        "- **Cluster 2**:\n",
        "    - Net Income is negative for stocks in this cluster.\n",
        "    - Estimated Shares Outstanding is low\n",
        "    - Net Cash Flow is negative for this cluster\n",
        "\n",
        "\n",
        "- **Cluster 3**:\n",
        "    - Net Income is very high\n",
        "    - Estimated Shares Outstanding is very high\n",
        "    - Net Cash Flow is low"
      ],
      "metadata": {
        "id": "5KzFTQ9LO3jc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-means vs Hierarchical Clustering"
      ],
      "metadata": {
        "id": "a9GxSQf-qH8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insights and Recommendations\n",
        "\n",
        "- K-Means took less time for execution\n",
        "- Both cluster techniques share the following:\n",
        "  - The majority of stocks are in both cluster 0 for each technique\n",
        "  - Both techniques share Apache Corp and Chesapeake Energy in Cluster 2\n",
        "  - Both techniques share Facebook in Cluster 3\n",
        "  - Hierarchial gave more distinct clusters than K-Means\n",
        "- Similar clusters from each algorithm:\n",
        "    - Net Cash Flow is negative for cluster 1 of both algorithms\n",
        "    - Net Income is negative for stocks in cluster 2 of both algorithms\n",
        "    - Net Cash Flow is negative for the cluster 2 of both algorithms  \n",
        "- As expected, Earnings Per Share is positively correlated with Current Price and Net Income\n",
        "- P/E Ratio is positively correlated with Current Price, Volatility and negatively correlated with Net Income and Earnings per Share.\n",
        "- Net Income is positively correlated with Earnings Per Share and Estimated Shares Outstanding and negatively correlated with Volatility and ROE\n",
        "- The sectors with the highest P/E ratios that help determine the value of a companys shares are:\n",
        "    - Energy\n",
        "    - IT\n",
        "    - Real Estate\n",
        "    - Health Care\n",
        "    - Consumer Discretionary\n",
        "\n",
        "- The sectors with high volatility and, therefore, are riskier investments are:\n",
        "    - Energy\n",
        "    - Materials\n",
        "    - IT\n",
        "- The sectors with the healthiest Cash Ratio are:\n",
        "    - IT\n",
        "    - Telecommunications Services\n",
        "    - Health Care\n",
        "- Health Care stocks saw the highest price increase by 9.59 followed by Consumer Staples and Information Technology\n",
        "- Energy stocks had the highest price drop of 10.22\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2BkZh6eHluZK"
      }
    }
  ]
}